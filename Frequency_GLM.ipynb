{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyM85p8mLzeXjmvGnBqBGdIy",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/IonZhao/Frequency_GLM/blob/main/Frequency_GLM.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "xC6Zi_QzZxII"
      },
      "outputs": [],
      "source": [
        "import random\n",
        "from collections import defaultdict\n",
        "\n",
        "class CharNGramLanguageModel:\n",
        "  def __init__(self, n, dataset):\n",
        "    self.n = n\n",
        "    # Our dataset, should be a list of text\n",
        "    self.dataset = dataset\n",
        "    # Our ngram model, a muti-dimension dictionary with default value 0 similar to dataframe\n",
        "    self.model = defaultdict(lambda: defaultdict(int))\n",
        "    # Train our model in initialization\n",
        "    self.train()\n",
        "\n",
        "  def train(self):\n",
        "    for text in self.dataset:\n",
        "      #Test preprocessing\n",
        "      text = text.lower() + ('<')\n",
        "      #From 0 to len-n\n",
        "      for i in range(len(text) - self.n):\n",
        "        # Get the ngram and next character\n",
        "        ngram = text[i:i+self.n]\n",
        "        next_char = text[i+self.n]\n",
        "        self.model[ngram][next_char] += 1\n",
        "\n",
        "        # Extension of the tableï¼Œ include character frequence and total count\n",
        "        self.model[ngram]['total'] += 1\n",
        "        self.model[0][next_char] += 1\n",
        "        self.model[0]['total'] += 1\n",
        "\n",
        "    # Convert counts to P\n",
        "    for ngram in self.model:\n",
        "      for char in self.model[ngram]:\n",
        "        if char != 'total':\n",
        "          self.model[ngram][char] = self.model[ngram][char] / self.model[ngram]['total']\n",
        "\n",
        "      # Remove the total column to indicate correct prob\n",
        "      del self.model[ngram]['total']\n",
        "\n",
        "  def generate_character(self, prompt):\n",
        "    # Ensure prompt is of length n\n",
        "    prompt = prompt[-self.n:]\n",
        "\n",
        "    if prompt in self.model:\n",
        "      # prompt = \"cat\", items={\"c\":0.3,\"a\":0.6....}\n",
        "      chars, probs = zip(*self.model[prompt].items())\n",
        "      # Choose a character from probality\n",
        "      next_char = random.choices(chars, probs)[0]\n",
        "    # if prompt doesn't exist\n",
        "    else:\n",
        "      # random choice based on character frequencies\n",
        "      if self.model[0]:\n",
        "        chars, probs = zip(*self.model[0].items())\n",
        "        next_char = random.choices(chars, probs)[0]\n",
        "      # if model[0] is empty, no data.\n",
        "      else:\n",
        "        next_char = random.choice('abcdefghijklmnopqrstuvwxyz')  # or any default char\n",
        "    return next_char\n",
        "\n",
        "  def generate(self, prompt, max_length=100):\n",
        "    result = prompt\n",
        "    for x in range(max_length):\n",
        "      next_char = self.generate_character(result)\n",
        "      # End of sentence symbol\n",
        "      if next_char == \"<\":\n",
        "          break\n",
        "      result += next_char\n",
        "    #print(self.model)\n",
        "    return result\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def load_dataset(filename):\n",
        "  with open(filename, 'r') as file:\n",
        "    # Read each line and strip extra whitespace\n",
        "    return [line.strip() for line in file.readlines()]\n",
        "\n",
        "def main():\n",
        "  # Load the dataset from the file\n",
        "  dataset_filename = '/content/sample_data/dataset.txt'\n",
        "  dataset = load_dataset(dataset_filename)\n",
        "\n",
        "  # Create the model and train\n",
        "  n = 3  # Example value for n\n",
        "  model = CharNGramLanguageModel(n, dataset)\n",
        "\n",
        "  # Get user input\n",
        "  prompt = input(\"Enter a prompt: \")\n",
        "\n",
        "  # Generate\n",
        "  generated_text = model.generate(prompt)\n",
        "  print(\"Generated text:\", generated_text)\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "  main()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2ioWt-_2azUE",
        "outputId": "158752b7-90c1-4b8c-9a78-3aad25b32004"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Enter a prompt: Hello\n",
            "Generated text: Hello  t out you never cared at it\n"
          ]
        }
      ]
    }
  ]
}